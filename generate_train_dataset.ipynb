{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huayinluo/Documents/code/gapjncsegmentation/gapvenv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torchio as tio\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "from models import *\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_z_y_x(file_name, pattern):\n",
    "    \"\"\" get z, y, x from file name (uses basename of file_name)\"\"\"\n",
    "    file_name = os.path.basename(file_name)\n",
    "    match = re.match(pattern, file_name)\n",
    "    if match:\n",
    "        if len(match.groups()) != 3:\n",
    "            return None\n",
    "        z, y, x = match.groups()\n",
    "        return int(z), int(y), int(x)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_dir=\"/Volumes/LaCie/zhenlab/gjsegmentation/gj_test_datasets/100_110_3x512x512/ground_truth\"\n",
    "img_dir=\"/Volumes/LaCie/zhenlab/gjsegmentation/gj_test_datasets/100_110_3x512x512/original\"\n",
    "save_dir=\"/Volumes/LaCie/filtered_100_110_3x512x512\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "if not os.path.exists(os.path.join(save_dir, \"original\", \"train\")):\n",
    "    os.makedirs(os.path.join(save_dir, \"original\", \"train\"), exist_ok=True)\n",
    "if not os.path.exists(os.path.join(save_dir, \"original\", \"valid\")):\n",
    "    os.makedirs(os.path.join(save_dir, \"original\", \"valid\"), exist_ok=True)\n",
    "if not os.path.exists(os.path.join(save_dir, \"ground_truth\", \"train\")):\n",
    "    os.makedirs(os.path.join(save_dir, \"ground_truth\", \"train\"), exist_ok=True)\n",
    "if not os.path.exists(os.path.join(save_dir, \"ground_truth\", \"valid\")):\n",
    "    os.makedirs(os.path.join(save_dir, \"ground_truth\", \"valid\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1271\n",
      "['z0_y0_x0.npy', 'z0_y0_x1024.npy', 'z0_y0_x1536.npy', 'z0_y0_x2048.npy', 'z0_y0_x2560.npy', 'z0_y0_x3072.npy', 'z0_y0_x3584.npy', 'z0_y0_x4096.npy', 'z0_y0_x4608.npy', 'z0_y0_x512.npy']\n",
      "['z0_y0_x0.npy', 'z0_y0_x1024.npy', 'z0_y0_x1536.npy', 'z0_y0_x2048.npy', 'z0_y0_x2560.npy', 'z0_y0_x3072.npy', 'z0_y0_x3584.npy', 'z0_y0_x4096.npy', 'z0_y0_x4608.npy', 'z0_y0_x512.npy']\n"
     ]
    }
   ],
   "source": [
    "img_paths = os.listdir(img_dir)\n",
    "gt_paths = os.listdir(gt_dir)\n",
    "print(len(img_paths))\n",
    "print(img_paths[:10])\n",
    "print(gt_paths[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved z9_y8192_x9216 | 1267/1271 | num saved 316\r"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "imgs=[]\n",
    "gts=[]\n",
    "num_saved = 0\n",
    "for i in range(len(img_paths)):\n",
    "    img_fp = img_paths[i]\n",
    "    gt_fp = gt_paths[i]\n",
    "    try:\n",
    "        img = np.load(os.path.join(img_dir, img_fp))\n",
    "        gt = np.load(os.path.join(gt_dir, gt_fp))\n",
    "    except:\n",
    "        continue\n",
    "    suffix = os.path.splitext(img_fp)[0]\n",
    "    print(f\"Saved {suffix} | {i}/{len(img_paths)} | num saved {num_saved}\", end=\"\\r\")\n",
    "    depth = gt.shape[0]\n",
    "    has_empty = False\n",
    "    for k in range(depth):\n",
    "        if len(np.unique(gt[k])) < 2:\n",
    "            has_empty = True\n",
    "    if not has_empty:\n",
    "        np.save(os.path.join(save_dir, \"original\", \"train\", f\"{suffix}.npy\"), img)\n",
    "        np.save(os.path.join(save_dir, \"ground_truth\", \"train\", f\"{suffix}.npy\"), gt)\n",
    "        num_saved += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316\n",
      "['z0_y1536_x3584.npy', 'z0_y1536_x4096.npy', 'z0_y1536_x4608.npy', 'z0_y2048_x2560.npy', 'z0_y2048_x3072.npy', 'z0_y2048_x3584.npy', 'z0_y2048_x4096.npy', 'z0_y2048_x4608.npy', 'z0_y2048_x5120.npy', 'z0_y2048_x6144.npy']\n",
      "['z0_y1536_x3584.npy', 'z0_y1536_x4096.npy', 'z0_y1536_x4608.npy', 'z0_y2048_x2560.npy', 'z0_y2048_x3072.npy', 'z0_y2048_x3584.npy', 'z0_y2048_x4096.npy', 'z0_y2048_x4608.npy', 'z0_y2048_x5120.npy', 'z0_y2048_x6144.npy']\n"
     ]
    }
   ],
   "source": [
    "img_paths = os.listdir(os.path.join(save_dir, \"original\", \"train\"))\n",
    "gt_paths = os.listdir(os.path.join(save_dir, \"ground_truth\", \"train\"))\n",
    "print(len(img_paths))\n",
    "print(img_paths[:10])\n",
    "print(gt_paths[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n",
      "[293  65  81 170 125 314 203 212 215 236]\n"
     ]
    }
   ],
   "source": [
    "num_imgs=len(img_paths)\n",
    "num_valid = int(0.1*num_imgs)\n",
    "indices = np.arange(num_imgs)\n",
    "np.random.shuffle(indices)\n",
    "valid_indices = indices[:num_valid]\n",
    "print(len(valid_indices))\n",
    "print(valid_indices[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir=\"/Volumes/LaCie/filtered_100_110_3x512x512_backup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moved 0/126\n",
      "moved 1/126\n",
      "moved 2/126\n",
      "moved 3/126\n",
      "moved 4/126\n",
      "moved 5/126\n",
      "moved 6/126\n",
      "moved 7/126\n",
      "moved 8/126\n",
      "moved 9/126\n",
      "moved 10/126\n",
      "moved 11/126\n",
      "moved 12/126\n",
      "moved 13/126\n",
      "moved 14/126\n",
      "moved 15/126\n",
      "moved 16/126\n",
      "moved 17/126\n",
      "moved 18/126\n",
      "moved 19/126\n",
      "moved 20/126\n",
      "moved 21/126\n",
      "moved 22/126\n",
      "moved 23/126\n",
      "moved 24/126\n",
      "moved 25/126\n",
      "moved 26/126\n",
      "moved 27/126\n",
      "moved 28/126\n",
      "moved 29/126\n",
      "moved 30/126\n",
      "moved 31/126\n",
      "moved 32/126\n",
      "moved 33/126\n",
      "moved 34/126\n",
      "moved 35/126\n",
      "moved 36/126\n",
      "moved 37/126\n",
      "moved 38/126\n",
      "moved 39/126\n",
      "moved 40/126\n",
      "moved 41/126\n",
      "moved 42/126\n",
      "moved 43/126\n",
      "moved 44/126\n",
      "moved 45/126\n",
      "moved 46/126\n",
      "moved 47/126\n",
      "moved 48/126\n",
      "moved 49/126\n",
      "moved 50/126\n",
      "moved 51/126\n",
      "moved 52/126\n",
      "moved 53/126\n",
      "moved 54/126\n",
      "moved 55/126\n",
      "moved 56/126\n",
      "moved 57/126\n",
      "moved 58/126\n",
      "moved 59/126\n",
      "moved 60/126\n",
      "moved 61/126\n",
      "moved 62/126\n",
      "moved 63/126\n",
      "moved 64/126\n",
      "moved 65/126\n",
      "moved 66/126\n",
      "moved 67/126\n",
      "moved 68/126\n",
      "moved 69/126\n",
      "moved 70/126\n",
      "moved 71/126\n",
      "moved 72/126\n",
      "moved 73/126\n",
      "moved 74/126\n",
      "moved 75/126\n",
      "moved 76/126\n",
      "moved 77/126\n",
      "moved 78/126\n",
      "moved 79/126\n",
      "moved 80/126\n",
      "moved 81/126\n",
      "moved 82/126\n",
      "moved 83/126\n",
      "moved 84/126\n",
      "moved 85/126\n",
      "moved 86/126\n",
      "moved 87/126\n",
      "moved 88/126\n",
      "moved 89/126\n",
      "moved 90/126\n",
      "moved 91/126\n",
      "moved 92/126\n",
      "moved 93/126\n",
      "moved 94/126\n",
      "moved 95/126\n",
      "moved 96/126\n",
      "moved 97/126\n",
      "moved 98/126\n",
      "moved 99/126\n",
      "moved 100/126\n",
      "moved 101/126\n",
      "moved 102/126\n",
      "moved 103/126\n",
      "moved 104/126\n",
      "moved 105/126\n",
      "moved 106/126\n",
      "moved 107/126\n",
      "moved 108/126\n",
      "moved 109/126\n",
      "moved 110/126\n",
      "moved 111/126\n",
      "moved 112/126\n",
      "moved 113/126\n",
      "moved 114/126\n",
      "moved 115/126\n",
      "moved 116/126\n",
      "moved 117/126\n",
      "moved 118/126\n",
      "moved 119/126\n",
      "moved 120/126\n",
      "moved 121/126\n",
      "moved 122/126\n",
      "moved 123/126\n",
      "moved 124/126\n",
      "moved 125/126\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(valid_indices)):\n",
    "    idx=valid_indices[i]\n",
    "    print(f\"moved {i}/{num_valid}\")\n",
    "    img_fp = img_paths[idx]\n",
    "    gt_fp = gt_paths[idx]\n",
    "    os.rename(os.path.join(save_dir, \"original\",\"train\", img_fp), os.path.join(save_dir, \"original\",\"valid\", img_fp))\n",
    "    os.rename(os.path.join(save_dir, \"ground_truth\",\"train\", gt_fp), os.path.join(save_dir, \"ground_truth\",\"valid\", gt_fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# -- args\n",
    "start_x = \n",
    "start_y = \n",
    "start_z = \n",
    "ending_depth = \n",
    "ending_height = \n",
    "ending_width = \n",
    "subvol_depth = \n",
    "subvol_height = \n",
    "subvol_width = \n",
    "mask_dir= \n",
    "img_dir= \n",
    "save_dir=\n",
    "if not os.path.exists(os.path.join(save_dir, \"visualize\")): \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_dir, \"original\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_dir, \"ground_truth\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_dir, \"pred\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_dir, \"visualize\"), exist_ok=True)\n",
    "    \n",
    "# -- get imgs & mask fp\n",
    "img_files = os.listdir(img_dir)\n",
    "mask_files = os.listdir(mask_dir)\n",
    "mask_pattern=r\"sem_dauer_2_gj_gt_s(\\d+).png\"\n",
    "img_pattern=r\"SEM_dauer_2_em_s(\\d+).png\"\n",
    "img_files = [os.path.join(img_dir, f) for f in img_files if f.endswith(\".png\")]\n",
    "mask_files = [os.path.join(mask_dir, f) for f in mask_files if f.endswith(\".png\")]\n",
    "\n",
    "# -- load model\n",
    "fp=\n",
    "model = UNet()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "model, optimizer, epoch, loss, batch_size, lr, focal_loss_weights = load_checkpoint(model, optimizer, fp)\n",
    "model = model.eval()\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -- get masks:\n",
    "i=0\n",
    "for z in range(start_z, ending_depth):\n",
    "    tmp_img = get_img_by_z(z, img_files, img_pattern)\n",
    "    tmp_mask = get_img_by_z(z, mask_files, mask_pattern)\n",
    "    if i == 0:\n",
    "        h, w = tmp_img.shape[0], tmp_img.shape[1]\n",
    "        full_volume_img = np.zeros((ending_depth-start_z, h, w))\n",
    "        full_volume_mask = np.zeros((ending_depth-start_z, h, w))\n",
    "        print(\"Created full img & mask\", full_volume_img.shape, full_volume_mask.shape)\n",
    "    full_volume_img[i] = tmp_img\n",
    "    full_volume_mask[i] = tmp_mask\n",
    "    i+=1\n",
    "    print(f\"done {z} z-slice\")\n",
    "print(\"full volume shape:\", full_volume_img.shape, full_volume_mask.shape)\n",
    "\n",
    "start_z = 0\n",
    "# ending_depth = full_volume_img.shape[0]\n",
    "if args.use_full_volume:\n",
    "    ending_height = full_volume_img.shape[1]\n",
    "    ending_width = full_volume_img.shape[2]\n",
    "print(\"subvolume shape:\", subvol_depth, subvol_height, subvol_width)\n",
    "print(\"ending:\", ending_depth, ending_height, ending_width)\n",
    "\n",
    "step_z = args.step_z\n",
    "step_y = args.step_y\n",
    "step_x = args.step_x\n",
    "while start_z < ending_depth:\n",
    "    end_z = start_z + subvol_depth\n",
    "    start_y = args.start_y\n",
    "    while start_y < ending_height:\n",
    "        end_y = start_y + subvol_height \n",
    "        start_x = args.start_x\n",
    "        while start_x < ending_width:\n",
    "            end_x = start_x + subvol_width\n",
    "            sub_volume_img = full_volume_img[start_z:end_z, start_y:end_y, start_x:end_x]\n",
    "            sub_volume_mask = full_volume_mask[start_z:end_z, start_y:end_y, start_x:end_x] # with confidence levels\n",
    "            sub_vol_depth, sub_vol_height, sub_vol_width = sub_volume_img.shape\n",
    "            image = torch.tensor(sub_volume_img).float().unsqueeze(0)\n",
    "            if (sub_vol_height < subvol_height) or (sub_vol_width < subvol_width) or (sub_vol_depth < subvol_depth):\n",
    "                image = tio.CropOrPad((subvol_depth, subvol_height, subvol_width))(image)\n",
    "                \n",
    "            try:\n",
    "                image = tio.ZNormalization()(image)\n",
    "                print(image.shape)\n",
    "                intermed_pred, sub_volume_pred = model(image)\n",
    "                binary_pred = torch.argmax(sub_volume_pred[0], dim=0) # (depth, height, width)\n",
    "                np.save(os.path.join(save_dir, \"original\", f\"z{start_z}_y{start_y}_x{start_x}.npy\"), sub_volume_img)\n",
    "                np.save(os.path.join(save_dir, \"ground_truth\", f\"z{start_z}_y{start_y}_x{start_x}.npy\"), sub_volume_mask)\n",
    "                np.save(os.path.join(save_dir, \"pred\", f\"z{start_z}_y{start_y}_x{start_x}.npy\"), sub_volume_pred.detach().cpu())            \n",
    "                fig, ax = plt.subplots(3, subvol_depth, figsize=(15,5), num=1)\n",
    "                visualize_3d_slice(sub_volume_img, ax[0], \"Image\")\n",
    "                visualize_3d_slice(sub_volume_mask, ax[1], \"Mask\")\n",
    "                visualize_3d_slice(binary_pred, ax[2], \"Pred\")\n",
    "                plt.savefig(os.path.join(save_dir, \"visualize\", f\"z{start_z}_y{start_y}_x{start_x}.png\"))\n",
    "                plt.close(\"all\")\n",
    "                print(f\"Saved z{start_z}-{end_z} y{start_y}-{end_y} x{start_x}-{end_x} subvolume\")\n",
    "            except:\n",
    "                print(f\"Skipping z{start_z}-{end_z} y{start_y}-{end_y} x{start_x}-{end_x}\")\n",
    "            start_x = start_x + step_x\n",
    "        start_y = start_y + step_y\n",
    "    start_z = start_z + step_z"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gapvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
